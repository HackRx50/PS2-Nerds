{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2f3e5-71c0-40aa-86d5-bbcd7b594fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12 11:45:54,843 - INFO - \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "2024-10-12 11:45:54,844 - INFO - \u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import base64\n",
    "import json\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # This line enables CORS for all routes\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def process_local_image(image_path):\n",
    "    try:\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "\n",
    "        # Read image with OpenCV\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(\"Failed to read image with OpenCV\")\n",
    "\n",
    "        # Convert to RGB (OpenCV uses BGR by default)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform image preprocessing\n",
    "        image_preprocessed = preprocess_image(image_rgb)\n",
    "\n",
    "        # Convert numpy array to bytes\n",
    "        is_success, img_buf_arr = cv2.imencode(\".jpg\", image_preprocessed)\n",
    "        if not is_success:\n",
    "            raise ValueError(\"Failed to encode image\")\n",
    "\n",
    "        byte_im = img_buf_arr.tobytes()\n",
    "\n",
    "        if len(byte_im) == 0:\n",
    "            raise ValueError(\"Processed image is empty\")\n",
    "\n",
    "        return byte_im\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing image: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Resize image if it's too large\n",
    "    max_size = 1600\n",
    "    height, width = image.shape[:2]\n",
    "    if height > max_size or width > max_size:\n",
    "        scale = max_size / max(height, width)\n",
    "        image = cv2.resize(image, (int(width * scale), int(height * scale)))\n",
    "\n",
    "    # Apply denoising\n",
    "    image = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
    "\n",
    "    # Enhance contrast\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    image = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    return image\n",
    "\n",
    "def analyze_document_from_file(image_path, api_key):\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-flash\",\n",
    "        generation_config={\n",
    "            \"temperature\": 0.2,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 32,\n",
    "            \"max_output_tokens\": 4096,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    image_data = process_local_image(image_path)\n",
    "    image_part = {\"mime_type\": \"image/jpeg\", \"data\": base64.b64encode(image_data).decode('utf-8')}\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    Analyze this document image in detail. Extract and categorize information based on the following criteria:\n",
    "\n",
    "    1. Text Analysis:\n",
    "       - Identify all text in the image.\n",
    "       - Detect any underlined text and specify which words/phrases are underlined.\n",
    "       - Identify segmented text (text split into separate boxes or sections).\n",
    "       - Detect if any text is cut off or partially visible.\n",
    "       - Identify any crossed-out or strikethrough text.\n",
    "\n",
    "    2. Symbol Detection:\n",
    "       - Detect the presence of checkboxes and whether they are checked or unchecked.\n",
    "       - Identify any stars (★) or asterisks (*) near text and specify their location (before or after the text).\n",
    "\n",
    "    3. Shape Analysis:\n",
    "       - Identify any shapes present in the document (circles, squares, triangles, etc.).\n",
    "       - Describe the relationship between shapes and nearby text.\n",
    "\n",
    "    4. Medication Information (if applicable):\n",
    "       - Extract all mentions of medications (e.g., med1, med2, med3, med4).\n",
    "       - For each medication, provide details and any associated shapes or symbols.\n",
    "\n",
    "    5. Form Structure:\n",
    "       - Identify form fields, labels, and their corresponding values.\n",
    "       - Detect any tables and describe their content.\n",
    "\n",
    "    6. Special Cases:\n",
    "       - Note any handwritten text and its location.\n",
    "       - Identify any logos, stamps, or signatures.\n",
    "       - Detect any QR codes or barcodes.\n",
    "\n",
    "    7. Image Quality Assessment:\n",
    "       - Evaluate the overall image quality (e.g., clear, blurry, skewed).\n",
    "       - Note any issues like poor contrast, shadows, or reflections.\n",
    "\n",
    "    Provide the analysis in the following JSON format:\n",
    "    {\n",
    "        \"text_analysis\": {\n",
    "            \"all_text\": [],\n",
    "            \"underlined_text\": [],\n",
    "            \"segmented_text\": [],\n",
    "            \"cut_off_text\": [],\n",
    "            \"crossed_out_text\": []\n",
    "        },\n",
    "        \"symbol_detection\": {\n",
    "            \"checkboxes\": [\n",
    "                {\"text\": \"\", \"status\": \"checked/unchecked\"}\n",
    "            ],\n",
    "            \"stars_asterisks\": [\n",
    "                {\"text\": \"\", \"symbol\": \"★/*\", \"position\": \"before/after\"}\n",
    "            ]\n",
    "        },\n",
    "        \"shape_analysis\": [\n",
    "            {\"shape\": \"\", \"description\": \"\", \"associated_text\": \"\"}\n",
    "        ],\n",
    "        \"medication_info\": {\n",
    "            \"med1\": {\"mentions\": [], \"details\": \"\", \"associated_elements\": \"\"},\n",
    "            \"med2\": {\"mentions\": [], \"details\": \"\", \"associated_elements\": \"\"},\n",
    "            \"med3\": {\"mentions\": [], \"details\": \"\", \"associated_elements\": \"\"},\n",
    "            \"med4\": {\"mentions\": [], \"details\": \"\", \"associated_elements\": \"\"}\n",
    "        },\n",
    "        \"form_structure\": {\n",
    "            \"fields\": [\n",
    "                {\"label\": \"\", \"value\": \"\"}\n",
    "            ],\n",
    "            \"tables\": [\n",
    "                {\"description\": \"\", \"content\": \"\"}\n",
    "            ]\n",
    "        },\n",
    "        \"special_cases\": {\n",
    "            \"handwritten_text\": [],\n",
    "            \"logos_stamps_signatures\": [],\n",
    "            \"qr_barcodes\": []\n",
    "        },\n",
    "        \"image_quality\": {\n",
    "            \"overall_quality\": \"\",\n",
    "            \"issues\": []\n",
    "        },\n",
    "        \"confidence_score\": 0\n",
    "    }\n",
    "\n",
    "    Analyze the image thoroughly and fill in all relevant sections of the JSON structure. If a section is not applicable, leave it as an empty list or string as appropriate.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_parts = [prompt_template, image_part]\n",
    "\n",
    "    max_retries = 5\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt_parts)\n",
    "            if not response or not response.text:\n",
    "                raise ValueError(\"Empty response from model\")\n",
    "\n",
    "            response_text = re.sub(r'^```json\\s*|\\s*```$', '', response.text.strip())\n",
    "            response_text = re.sub(r'^```\\s*|\\s*```$', '', response_text).replace('\\n', ' ').replace('\\r', '').strip()\n",
    "\n",
    "            result = json.loads(response_text)\n",
    "            \n",
    "            # Add confidence score based on the number of retries\n",
    "            result['confidence_score'] = 1 - (attempt / max_retries)\n",
    "            \n",
    "            return result\n",
    "\n",
    "        except json.JSONDecodeError as je:\n",
    "            logging.warning(f\"JSON decoding error (attempt {attempt + 1}): {str(je)}\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error during analysis (attempt {attempt + 1}): {str(e)}\")\n",
    "\n",
    "        if attempt < max_retries - 1:\n",
    "            wait_time = 2 ** attempt\n",
    "            logging.info(f\"Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    raise Exception(\"Failed to analyze document after maximum retries\")\n",
    "\n",
    "@app.route('/analyze', methods=['POST'])\n",
    "def analyze_document():\n",
    "    try:\n",
    "        # Get the image path from the request\n",
    "        data = request.json\n",
    "        image_path = data.get('image_path')\n",
    "        \n",
    "        if not image_path:\n",
    "            return jsonify({\"error\": \"No image path provided\"}), 400\n",
    "        \n",
    "        # Replace with your actual Gemini API key\n",
    "        api_key = \"AIzaSyCQrYGVRTNivr4Dh_xhJLkVovy6kDEFhKY\"\n",
    "        \n",
    "        # Analyze the document\n",
    "        result = analyze_document_from_file(image_path, api_key)\n",
    "        \n",
    "        return jsonify(result)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {str(e)}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4afe25-f43c-4d58-8533-7c33c17e14ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-pythonNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\anjal\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86efda9-1349-40c9-9f53-8ea97584c0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
